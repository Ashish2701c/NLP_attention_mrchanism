{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "nlp-attn-mech-fin0.ipynb",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "8d8GNbZAEj5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as  np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "from prettytable import PrettyTable\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import warnings\n",
        "from tensorflow.keras.activations import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import *\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T13:40:51.379134Z",
          "iopub.execute_input": "2022-07-12T13:40:51.379653Z",
          "iopub.status.idle": "2022-07-12T13:40:58.295220Z",
          "shell.execute_reply.started": "2022-07-12T13:40:51.379538Z",
          "shell.execute_reply": "2022-07-12T13:40:58.294234Z"
        },
        "trusted": true,
        "id": "Vjo16coYEj5J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../input/itaeng/ita.txt', 'r', encoding=\"utf8\") as file:\n",
        "    english = []\n",
        "    italian = []\n",
        "    for i in file.readlines():\n",
        "        english.append(i.split(\"\\t\")[0])\n",
        "        italian.append(i.split(\"\\t\")[1])\n",
        "data = pd.DataFrame({'english': english, 'italian': italian})\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T13:51:04.421923Z",
          "iopub.execute_input": "2022-07-12T13:51:04.422274Z",
          "iopub.status.idle": "2022-07-12T13:51:05.028766Z",
          "shell.execute_reply.started": "2022-07-12T13:51:04.422245Z",
          "shell.execute_reply": "2022-07-12T13:51:05.027800Z"
        },
        "trusted": true,
        "id": "YF9omzoYEj5L",
        "outputId": "8e9e9b14-4648-4a07-a743-2d5acd45c32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 11,
          "output_type": "execute_result",
          "data": {
            "text/plain": "  english   italian\n0     Hi.     Ciao!\n1     Hi.     Ciao.\n2    Run!    Corri!\n3    Run!    Corra!\n4    Run!  Correte!",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>italian</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi.</td>\n      <td>Ciao!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hi.</td>\n      <td>Ciao.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Corri!</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Run!</td>\n      <td>Corra!</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Run!</td>\n      <td>Correte!</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # I have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "data['english'] = data['english'].apply(preprocess)\n",
        "data['italian'] = data['italian'].apply(preprocess_ita)\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T13:51:07.984283Z",
          "iopub.execute_input": "2022-07-12T13:51:07.984615Z",
          "iopub.status.idle": "2022-07-12T13:51:26.841708Z",
          "shell.execute_reply.started": "2022-07-12T13:51:07.984587Z",
          "shell.execute_reply": "2022-07-12T13:51:26.840758Z"
        },
        "trusted": true,
        "id": "CvNYCz05Ej5N",
        "outputId": "4f5b9cb6-8d21-4ac1-d3bd-e16a818aba16"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "  english  italian\n0      hi     ciao\n1      hi     ciao\n2     run    corri\n3     run    corra\n4     run  correte",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>italian</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hi</td>\n      <td>ciao</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>hi</td>\n      <td>ciao</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>run</td>\n      <td>corri</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>run</td>\n      <td>corra</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>run</td>\n      <td>correte</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop_duplicates(subset=['english','italian'])\n",
        "data = data.reset_index(drop=True)\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T13:51:30.632757Z",
          "iopub.execute_input": "2022-07-12T13:51:30.633107Z",
          "iopub.status.idle": "2022-07-12T13:51:30.826352Z",
          "shell.execute_reply.started": "2022-07-12T13:51:30.633075Z",
          "shell.execute_reply": "2022-07-12T13:51:30.825318Z"
        },
        "trusted": true,
        "id": "D5QvOyipEj5Q",
        "outputId": "11190091-8b9b-47c5-b9ae-f8fa3132c24a"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "  english  italian\n0      hi     ciao\n1     run    corri\n2     run    corra\n3     run  correte\n4     who      chi",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>english</th>\n      <th>italian</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>hi</td>\n      <td>ciao</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>run</td>\n      <td>corri</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>run</td>\n      <td>corra</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>run</td>\n      <td>correte</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>who</td>\n      <td>chi</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['italian_len'] = data['italian'].str.split().apply(len)\n",
        "data = data[data['italian_len'] < 25]\n",
        "\n",
        "data['english_len'] = data['english'].str.split().apply(len)\n",
        "data = data[data['english_len'] < 25]\n",
        "\n",
        "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
        "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
        "data['italian'] = '<start> ' + data['italian'].astype(str) + ' <end>'\n",
        "\n",
        "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T13:51:36.054025Z",
          "iopub.execute_input": "2022-07-12T13:51:36.054564Z",
          "iopub.status.idle": "2022-07-12T13:51:38.391732Z",
          "shell.execute_reply.started": "2022-07-12T13:51:36.054532Z",
          "shell.execute_reply": "2022-07-12T13:51:38.390883Z"
        },
        "trusted": true,
        "id": "zBjJhhlpEj5R",
        "outputId": "9132dcdd-ffa7-40ad-cad6-b1cde0e1fe7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 14,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                 italian  english_inp english_out\n0     <start> ciao <end>   <start> hi    hi <end>\n1    <start> corri <end>  <start> run   run <end>\n2    <start> corra <end>  <start> run   run <end>\n3  <start> correte <end>  <start> run   run <end>\n4      <start> chi <end>  <start> who   who <end>",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>italian</th>\n      <th>english_inp</th>\n      <th>english_out</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;start&gt; ciao &lt;end&gt;</td>\n      <td>&lt;start&gt; hi</td>\n      <td>hi &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>&lt;start&gt; corri &lt;end&gt;</td>\n      <td>&lt;start&gt; run</td>\n      <td>run &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>&lt;start&gt; corra &lt;end&gt;</td>\n      <td>&lt;start&gt; run</td>\n      <td>run &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>&lt;start&gt; correte &lt;end&gt;</td>\n      <td>&lt;start&gt; run</td>\n      <td>run &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>&lt;start&gt; chi &lt;end&gt;</td>\n      <td>&lt;start&gt; who</td>\n      <td>who &lt;end&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, validation = train_test_split(data, test_size=0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:07:55.210586Z",
          "iopub.execute_input": "2022-07-12T14:07:55.210963Z",
          "iopub.status.idle": "2022-07-12T14:07:55.314488Z",
          "shell.execute_reply.started": "2022-07-12T14:07:55.210926Z",
          "shell.execute_reply": "2022-07-12T14:07:55.313383Z"
        },
        "trusted": true,
        "id": "wutp8tJcEj5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.shape, validation.shape)\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\n",
        "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:07:58.847506Z",
          "iopub.execute_input": "2022-07-12T14:07:58.848404Z",
          "iopub.status.idle": "2022-07-12T14:07:58.855365Z",
          "shell.execute_reply.started": "2022-07-12T14:07:58.848364Z",
          "shell.execute_reply": "2022-07-12T14:07:58.854193Z"
        },
        "trusted": true,
        "id": "vHo3Fqw7Ej5T",
        "outputId": "88dadae8-7b5c-41f8-e0f6-d8bbac8fc5b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(280740, 3) (70185, 3)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T07:40:52.721690Z",
          "iopub.execute_input": "2022-07-12T07:40:52.722155Z",
          "iopub.status.idle": "2022-07-12T07:40:52.737860Z",
          "shell.execute_reply.started": "2022-07-12T07:40:52.722114Z",
          "shell.execute_reply": "2022-07-12T07:40:52.736910Z"
        },
        "trusted": true,
        "id": "TT8JWvCxEj5U",
        "outputId": "e5295af3-2c2b-444c-faf5-9d42cec492a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                  italian  \\\n239709  <start> non dimentichi di chiudere la porta <end>   \n47529                 <start> io conosco quel suono <end>   \n332035  <start> non sono il fidanzato di mary sono sol...   \n137931            <start> è inutile chiederlo a tom <end>   \n145546            <start> dovreste andare lì adesso <end>   \n\n                                              english_inp  \\\n239709      <start> do not forget to close the door <end>   \n47529                           <start> i know that sound   \n332035  <start> i am not mary is boyfriend i am just a...   \n137931                   <start> it is useless to ask tom   \n145546                    <start> you should go there now   \n\n                                              english_out  \n239709        do not forget to close the door <end> <end>  \n47529                             i know that sound <end>  \n332035  i am not mary is boyfriend i am just a friend ...  \n137931                     it is useless to ask tom <end>  \n145546                      you should go there now <end>  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>italian</th>\n      <th>english_inp</th>\n      <th>english_out</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>239709</th>\n      <td>&lt;start&gt; non dimentichi di chiudere la porta &lt;end&gt;</td>\n      <td>&lt;start&gt; do not forget to close the door &lt;end&gt;</td>\n      <td>do not forget to close the door &lt;end&gt; &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>47529</th>\n      <td>&lt;start&gt; io conosco quel suono &lt;end&gt;</td>\n      <td>&lt;start&gt; i know that sound</td>\n      <td>i know that sound &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>332035</th>\n      <td>&lt;start&gt; non sono il fidanzato di mary sono sol...</td>\n      <td>&lt;start&gt; i am not mary is boyfriend i am just a...</td>\n      <td>i am not mary is boyfriend i am just a friend ...</td>\n    </tr>\n    <tr>\n      <th>137931</th>\n      <td>&lt;start&gt; è inutile chiederlo a tom &lt;end&gt;</td>\n      <td>&lt;start&gt; it is useless to ask tom</td>\n      <td>it is useless to ask tom &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>145546</th>\n      <td>&lt;start&gt; dovreste andare lì adesso &lt;end&gt;</td>\n      <td>&lt;start&gt; you should go there now</td>\n      <td>you should go there now &lt;end&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T07:41:01.064171Z",
          "iopub.execute_input": "2022-07-12T07:41:01.064527Z",
          "iopub.status.idle": "2022-07-12T07:41:01.075498Z",
          "shell.execute_reply.started": "2022-07-12T07:41:01.064494Z",
          "shell.execute_reply": "2022-07-12T07:41:01.074471Z"
        },
        "trusted": true,
        "id": "tEErVlqgEj5V",
        "outputId": "bf8cc37a-5bdd-472a-b5b5-96db947e590e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 17,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                  italian  \\\n202131      <start> per favore scopri dove si trova <end>   \n148016         <start> mi dia una bottiglia di vino <end>   \n336265  <start> io devo fare i miei compiti invece di ...   \n118724              <start> ho un po di raffreddore <end>   \n243651  <start> sono convinta che tom non sia colpevol...   \n\n                                              english_inp  \\\n202131                <start> please find out where he is   \n148016                   <start> give me a bottle of wine   \n336265  <start> i have to do my homework instead of go...   \n118724                     <start> i have a bit of a cold   \n243651           <start> i am convinced tom is not guilty   \n\n                                              english_out  \n202131                  please find out where he is <end>  \n148016                     give me a bottle of wine <end>  \n336265  i have to do my homework instead of going out ...  \n118724                       i have a bit of a cold <end>  \n243651             i am convinced tom is not guilty <end>  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>italian</th>\n      <th>english_inp</th>\n      <th>english_out</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>202131</th>\n      <td>&lt;start&gt; per favore scopri dove si trova &lt;end&gt;</td>\n      <td>&lt;start&gt; please find out where he is</td>\n      <td>please find out where he is &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>148016</th>\n      <td>&lt;start&gt; mi dia una bottiglia di vino &lt;end&gt;</td>\n      <td>&lt;start&gt; give me a bottle of wine</td>\n      <td>give me a bottle of wine &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>336265</th>\n      <td>&lt;start&gt; io devo fare i miei compiti invece di ...</td>\n      <td>&lt;start&gt; i have to do my homework instead of go...</td>\n      <td>i have to do my homework instead of going out ...</td>\n    </tr>\n    <tr>\n      <th>118724</th>\n      <td>&lt;start&gt; ho un po di raffreddore &lt;end&gt;</td>\n      <td>&lt;start&gt; i have a bit of a cold</td>\n      <td>i have a bit of a cold &lt;end&gt;</td>\n    </tr>\n    <tr>\n      <th>243651</th>\n      <td>&lt;start&gt; sono convinta che tom non sia colpevol...</td>\n      <td>&lt;start&gt; i am convinced tom is not guilty</td>\n      <td>i am convinced tom is not guilty &lt;end&gt;</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ita_lengths = train['italian'].str.split().apply(len)\n",
        "eng_lengths = train['english_inp'].str.split().apply(len)\n",
        "import seaborn as sns\n",
        "sns.kdeplot(ita_lengths)\n",
        "plt.show()\n",
        "sns.kdeplot(eng_lengths)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:08:05.105628Z",
          "iopub.execute_input": "2022-07-12T14:08:05.105992Z",
          "iopub.status.idle": "2022-07-12T14:08:09.442753Z",
          "shell.execute_reply.started": "2022-07-12T14:08:05.105961Z",
          "shell.execute_reply": "2022-07-12T14:08:09.441803Z"
        },
        "trusted": true,
        "id": "WJNnFghcEj5V",
        "outputId": "6d3e75fd-a609-432c-cdaf-8815887f650c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<Figure size 432x288 with 1 Axes>",
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_ita = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_ita.fit_on_texts(train['italian'].values)\n",
        "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\n",
        "tknizer_eng.fit_on_texts(train['english_inp'].values)\n",
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\n",
        "print(vocab_size_eng)\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\n",
        "print(vocab_size_ita)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:08:09.444471Z",
          "iopub.execute_input": "2022-07-12T14:08:09.444923Z",
          "iopub.status.idle": "2022-07-12T14:08:16.767356Z",
          "shell.execute_reply.started": "2022-07-12T14:08:09.444887Z",
          "shell.execute_reply": "2022-07-12T14:08:16.766263Z"
        },
        "trusted": true,
        "id": "6VNE8f8iEj5W",
        "outputId": "95fb7c50-615e-4ea3-ba6b-76e825630523"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "13099\n26720\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:08:16.769216Z",
          "iopub.execute_input": "2022-07-12T14:08:16.769766Z",
          "iopub.status.idle": "2022-07-12T14:08:16.777038Z",
          "shell.execute_reply.started": "2022-07-12T14:08:16.769727Z",
          "shell.execute_reply": "2022-07-12T14:08:16.775881Z"
        },
        "trusted": true,
        "id": "jRGxZ7s7Ej5W",
        "outputId": "2461974d-5513-4348-a9dc-4f64d17ac6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(1, 10337)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font"
      ],
      "metadata": {
        "id": "_ZNCmC4vEj5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ],
      "metadata": {
        "id": "Uz2bBvjZEj5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "\n",
        "    def __init__(self, inp_vocab_size, embedding_size, lstm_size, input_length):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.inp_vocab_size = inp_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embed = Embedding(input_dim = self.inp_vocab_size, output_dim = self.embedding_size,\n",
        "                               input_length = self.input_length, name=\"Encoder_Embedding\")\n",
        "        self.lstm = LSTM(units = self.lstm_size, return_sequences = True, return_state = True, name=\"Encoder_LSTM\")\n",
        "        \n",
        "    def call(self, input_sequence, states = None):\n",
        "          \n",
        "        embed_out = self.embed(input_sequence)\n",
        "        lstm_out, lstm_h, lstm_c = self.lstm(embed_out, states)\n",
        "        return lstm_out, lstm_h, lstm_c\n",
        "\n",
        "    def initialize_states(self,batch_size):\n",
        "        states_h = tf.keras.backend.zeros((batch_size, self.lstm_size))\n",
        "        state_c = tf.keras.backend.zeros((batch_size, self.lstm_size))\n",
        "        return states_h, state_c   \n",
        "\n",
        "      \n",
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size,embedding_size,lstm_size,input_length):\n",
        "        super().__init__()\n",
        "        self.inp_vocab_size = out_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.lstm_size = lstm_size\n",
        "        self.embed = Embedding(input_dim = self.inp_vocab_size, output_dim = self.embedding_size,\n",
        "                               input_length = self.input_length, name=\"Decoder_Embedding\")\n",
        "        self.lstm = LSTM(units = self.lstm_size, return_sequences = True, return_state = True, name=\"Decoder_LSTM\")\n",
        "  \n",
        "    def call(self, output_sequence, initial_states):\n",
        "        embed_out = self.embed(output_sequence)\n",
        "        lstm_out, lstm_h, lstm_c = self.lstm(embed_out, initial_states)\n",
        "        return lstm_out, lstm_h, lstm_c  \n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:08:25.134944Z",
          "iopub.execute_input": "2022-07-12T14:08:25.135374Z",
          "iopub.status.idle": "2022-07-12T14:08:25.152681Z",
          "shell.execute_reply.started": "2022-07-12T14:08:25.135338Z",
          "shell.execute_reply": "2022-07-12T14:08:25.151601Z"
        },
        "trusted": true,
        "id": "bdPapspPEj5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:49:58.784789Z",
          "iopub.execute_input": "2022-07-12T14:49:58.785548Z",
          "iopub.status.idle": "2022-07-12T14:49:58.815809Z",
          "shell.execute_reply.started": "2022-07-12T14:49:58.785494Z",
          "shell.execute_reply": "2022-07-12T14:49:58.814762Z"
        },
        "trusted": true,
        "id": "90pRhxP8Ej5Z",
        "outputId": "fa6f35b6-ef9e-4719-a376-be8efc16bc99"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "True\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    assert(output.shape==(batch_size,input_length,dec_units))\n",
        "    return True\n",
        "print(grader_decoder())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:50:40.836495Z",
          "iopub.execute_input": "2022-07-12T14:50:40.836826Z",
          "iopub.status.idle": "2022-07-12T14:50:40.863899Z",
          "shell.execute_reply.started": "2022-07-12T14:50:40.836797Z",
          "shell.execute_reply": "2022-07-12T14:50:40.863024Z"
        },
        "trusted": true,
        "id": "krylJ05KEj5a",
        "outputId": "4eba8cb8-88ec-4c8b-9124-dba71e047418"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "True\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_decoder(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, encoder_inputs_length, decoder_inputs_length, output_vocab_size):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(inp_vocab_size = vocab_size_ita+1, embedding_size = 300, input_length = encoder_inputs_length,\n",
        "                               lstm_size = 512)\n",
        "        self.decoder = Decoder(out_vocab_size = vocab_size_eng+1, embedding_size = 300, input_length = decoder_inputs_length,\n",
        "                               lstm_size = 512)\n",
        "        self.dense = Dense(output_vocab_size, activation = 'softmax')\n",
        "    \n",
        "    def call(self, data):\n",
        "        inp, targ = data[0], data[1]\n",
        "        enc_out, state_h, state_c = self.encoder(inp)\n",
        "        dec_out, _, _ = self.decoder(targ, [state_h, state_c])\n",
        "        out = self.dense(dec_out)\n",
        "        return out "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:08:30.845559Z",
          "iopub.execute_input": "2022-07-12T14:08:30.845916Z",
          "iopub.status.idle": "2022-07-12T14:08:30.853626Z",
          "shell.execute_reply.started": "2022-07-12T14:08:30.845879Z",
          "shell.execute_reply": "2022-07-12T14:08:30.852465Z"
        },
        "trusted": true,
        "id": "tXXQniMGEj5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['italian'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len+1, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len+1, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:08:32.702043Z",
          "iopub.execute_input": "2022-07-12T14:08:32.702391Z",
          "iopub.status.idle": "2022-07-12T14:08:32.717549Z",
          "shell.execute_reply.started": "2022-07-12T14:08:32.702362Z",
          "shell.execute_reply": "2022-07-12T14:08:32.716529Z"
        },
        "trusted": true,
        "id": "aXmvHJoTEj5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1024\n",
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 20)\n",
        "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 20)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=batch_size)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "print(train_dataloader[0][0][0].shape, train_dataloader[0][0][1].shape, train_dataloader[0][1].shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:08:34.596156Z",
          "iopub.execute_input": "2022-07-12T14:08:34.596923Z",
          "iopub.status.idle": "2022-07-12T14:08:35.011014Z",
          "shell.execute_reply.started": "2022-07-12T14:08:34.596849Z",
          "shell.execute_reply": "2022-07-12T14:08:35.010100Z"
        },
        "trusted": true,
        "id": "sfUXEaW-Ej5c",
        "outputId": "486f892d-4a28-4a1e-e4cb-45843dcaa6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(1024, 20) (1024, 21) (1024, 21)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## defining callbacks and model and then compiling it\n",
        "log_dir = \"logs/fit/\"\n",
        "earl_stp = tf.keras.callbacks.EarlyStopping(patience = 3, restore_best_weights = True)\n",
        "\n",
        "model1 = Encoder_decoder(encoder_inputs_length = 20, decoder_inputs_length = 20, output_vocab_size = vocab_size_eng)          \n",
        "model1.compile('adam', loss = 'sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:08:41.195755Z",
          "iopub.execute_input": "2022-07-12T14:08:41.196174Z",
          "iopub.status.idle": "2022-07-12T14:08:43.921914Z",
          "shell.execute_reply.started": "2022-07-12T14:08:41.196140Z",
          "shell.execute_reply": "2022-07-12T14:08:43.921037Z"
        },
        "trusted": true,
        "id": "XWhI-JZUEj5c",
        "outputId": "9a93dff8-5233-4758-db7d-35a06443340f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2022-07-12 14:08:41.295168: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-12 14:08:41.411260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-12 14:08:41.412078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-12 14:08:41.413713: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-07-12 14:08:41.414010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-12 14:08:41.414688: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-12 14:08:41.415422: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-12 14:08:43.566783: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-12 14:08:43.567598: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-12 14:08:43.568295: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-07-12 14:08:43.568950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15403 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1.fit(train_dataloader, validation_data=test_dataloader,\n",
        "           steps_per_epoch = 150, epochs=10,\n",
        "           validation_steps = 40, callbacks = [earl_stp])\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:28:56.377894Z",
          "iopub.execute_input": "2022-07-12T14:28:56.378545Z",
          "iopub.status.idle": "2022-07-12T14:37:11.601888Z",
          "shell.execute_reply.started": "2022-07-12T14:28:56.378512Z",
          "shell.execute_reply": "2022-07-12T14:37:11.600778Z"
        },
        "trusted": true,
        "id": "oxu8x-zrEj5c",
        "outputId": "62ce5170-267e-416a-d923-d54902ac0c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n150/150 [==============================] - 45s 297ms/step - loss: 0.5817 - val_loss: 0.5792\nEpoch 2/10\n150/150 [==============================] - 44s 295ms/step - loss: 0.5086 - val_loss: 0.5181\nEpoch 3/10\n150/150 [==============================] - 39s 262ms/step - loss: 0.4411 - val_loss: 0.4587\nEpoch 4/10\n150/150 [==============================] - 40s 263ms/step - loss: 0.3795 - val_loss: 0.4089\nEpoch 5/10\n150/150 [==============================] - 40s 264ms/step - loss: 0.3287 - val_loss: 0.3672\nEpoch 6/10\n150/150 [==============================] - 40s 264ms/step - loss: 0.2854 - val_loss: 0.3346\nEpoch 7/10\n150/150 [==============================] - 44s 294ms/step - loss: 0.2507 - val_loss: 0.3074\nEpoch 8/10\n150/150 [==============================] - 40s 263ms/step - loss: 0.2204 - val_loss: 0.2871\nEpoch 9/10\n150/150 [==============================] - 40s 267ms/step - loss: 0.1949 - val_loss: 0.2699\nEpoch 10/10\n150/150 [==============================] - 44s 296ms/step - loss: 0.1778 - val_loss: 0.2540\n",
          "output_type": "stream"
        },
        {
          "execution_count": 50,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7fe551cbbad0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_sentence):\n",
        "    out_text = ''\n",
        "    seq = tknizer_ita.texts_to_sequences([input_sentence]) \n",
        "    pad = pad_sequences(seq, maxlen = 20, dtype='int32', padding='post')\n",
        "    enc_out, state_h, state_c = model1.encoder(pad)\n",
        "    intial = np.zeros((1,1), dtype = 'float32')\n",
        "    intial[0, 0] = tknizer_eng.word_index['<start>']\n",
        "    states = [state_h, state_c]\n",
        "    \n",
        "    for i in range(20):\n",
        "        predicted_out, state_h, state_c = model1.decoder(intial, initial_states = states)\n",
        "        out = model1.dense(predicted_out).numpy()\n",
        "        out = out.reshape(out.shape[-1])\n",
        "        states = [state_h, state_c] # Update State\n",
        "        out = np.argmax(out)\n",
        "        intial = np.zeros((1, 1), dtype = 'float32')\n",
        "        if tknizer_eng.index_word[out] == '<end>' or i == 20:\n",
        "            break\n",
        "        intial[0, 0] = out #Update decoder input\n",
        "        out_text += tknizer_eng.index_word[out] + ' '\n",
        "    return out_text"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:37:11.603976Z",
          "iopub.execute_input": "2022-07-12T14:37:11.604333Z",
          "iopub.status.idle": "2022-07-12T14:37:11.614187Z",
          "shell.execute_reply.started": "2022-07-12T14:37:11.604298Z",
          "shell.execute_reply": "2022-07-12T14:37:11.613083Z"
        },
        "trusted": true,
        "id": "tZIswL-UEj5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.translate.bleu_score as bleu\n",
        "bleu_score = []\n",
        "for n in (np.random.randint(0, len(validation), 5)):\n",
        "    query = validation.italian.values[n]\n",
        "    pred = predict(query)\n",
        "    ground = validation.english_inp.values[n]\n",
        "    ground_ = nltk.tokenize.casual.casual_tokenize(ground)\n",
        "    pred_ = nltk.tokenize.casual.casual_tokenize(pred)\n",
        "    bleu_score.append(nltk.translate.bleu_score.sentence_bleu([ground_], pred_)) \n",
        "    print(\"-\"*50)\n",
        "    print(\"italian Sentence: \", query)\n",
        "    print(\"Actual translation: \", ground)\n",
        "    print(\"Predicted Translation: \", pred)\n",
        "print(\"BLEU score :\", np.mean(bleu_score))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:37:11.615509Z",
          "iopub.execute_input": "2022-07-12T14:37:11.616335Z",
          "iopub.status.idle": "2022-07-12T14:37:11.819501Z",
          "shell.execute_reply.started": "2022-07-12T14:37:11.616299Z",
          "shell.execute_reply": "2022-07-12T14:37:11.818549Z"
        },
        "trusted": true,
        "id": "kemK5-y1Ej5d",
        "outputId": "23fa448a-563b-413c-acf5-cbdca93e12f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--------------------------------------------------\nitalian Sentence:  <start> parigi è la capitale della francia <end>\nActual translation:  <start> paris is the capital of france\nPredicted Translation:  paris is the capital of france \n--------------------------------------------------\nitalian Sentence:  <start> tom mi assicurò che la pistola non era carica <end>\nActual translation:  <start> tom assured me the gun was not loaded\nPredicted Translation:  tom assured me the gun is not a gun \n--------------------------------------------------\nitalian Sentence:  <start> lui ha risolto il problema da solo <end>\nActual translation:  <start> he solved the problem by himself\nPredicted Translation:  he solved the problem by himself \n--------------------------------------------------\nitalian Sentence:  <start> ho imparato la mia lezione <end>\nActual translation:  <start> i learned my lesson\nPredicted Translation:  i have learned my lesson \n--------------------------------------------------\nitalian Sentence:  <start> negli autobus affollati i giovani dovrebbero cedere il loro posto agli anziani <end>\nActual translation:  <start> on crowded buses young people should give their seats to old people\nPredicted Translation:  the young hurry to the party should walk by the moon \nBLEU score : 0.6733787580806078\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task -2: Including Attention mechanisum"
      ],
      "metadata": {
        "id": "V03Fn5VQEj5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Use the preprocessed data from Task-1\n",
        "\n",
        "2. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
        "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
        "\n",
        "5. Using attention weights, you can plot the attention plots, \n",
        "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
        "\n",
        "6. The attention layer has to be written by yourself only. \n",
        "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
        "\n",
        "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
        "\n",
        "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
        " Check the reference notebook for better understanding.\n",
        "\n",
        "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "11. Resources:\n",
        "    a. Check the reference notebook\n",
        "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
        "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
        "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
        "    "
      ],
      "metadata": {
        "id": "xjSELJluEj5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ],
      "metadata": {
        "id": "EAzH3H3YEj5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ],
      "metadata": {
        "id": "Apfl6eF7Ej5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,inp_vocab_size,embedding_size,lstm_size,input_length):\n",
        "\n",
        "        #Initialize Embedding layer\n",
        "        #Intialize Encoder LSTM layer\n",
        "        super().__init__()\n",
        "        self.vocab_size = inp_vocab_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.input_length = input_length\n",
        "        self.lstm_size= lstm_size\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "\n",
        "    def call(self,input_sequence,states):\n",
        "        input_embedd = self.embedding(input_sequence)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(input_embedd,initial_state=states)\n",
        "        return self.lstm_output, self.lstm_state_h,self.lstm_state_c\n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "        initial_state_h=tf.zeros([batch_size,self.lstm_size],dtype=tf.dtypes.float32)\n",
        "        initial_state_c=tf.zeros([batch_size,self.lstm_size],dtype=tf.dtypes.float32)\n",
        "        return [initial_state_h , initial_state_c]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T08:16:35.016024Z",
          "iopub.execute_input": "2022-07-12T08:16:35.016763Z",
          "iopub.status.idle": "2022-07-12T08:16:35.026859Z",
          "shell.execute_reply.started": "2022-07-12T08:16:35.016721Z",
          "shell.execute_reply": "2022-07-12T08:16:35.025990Z"
        },
        "trusted": true,
        "id": "KgsAmckhEj5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ],
      "metadata": {
        "id": "zUSgvGfwEj5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:54:12.637738Z",
          "iopub.execute_input": "2022-07-12T14:54:12.638617Z",
          "iopub.status.idle": "2022-07-12T14:54:12.665920Z",
          "shell.execute_reply.started": "2022-07-12T14:54:12.638584Z",
          "shell.execute_reply": "2022-07-12T14:54:12.664930Z"
        },
        "trusted": true,
        "id": "GFLuzwWtEj5e",
        "outputId": "4d8a601b-84eb-4a58-9f02-5d3fbf59f6d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "True\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>**Attention**</font>"
      ],
      "metadata": {
        "id": "1-pvqKyhEj5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "    def __init__(self, scoring_function, att_units):\n",
        "        super().__init__()\n",
        "        self.scoring_function = scoring_function\n",
        "        self.att_units = att_units\n",
        "\n",
        "        if self.scoring_function == 'concat':\n",
        "            self.W11 = tf.keras.layers.Dense(self.att_units)\n",
        "            self.W21 = tf.keras.layers.Dense(self.att_units)\n",
        "            self.v = tf.keras.layers.Dense(1)\n",
        "            \n",
        "        elif self.scoring_function == 'general':\n",
        "            self.W1 = tf.keras.layers.Dense(self.att_units)\n",
        "\n",
        "  \n",
        "    def call(self,decoder_hidden_state,encoder_output):\n",
        "        if self.scoring_function == 'dot':\n",
        "            decoder_hidden_state = tf.expand_dims(decoder_hidden_state,2)\n",
        "            similarity = tf.matmul(encoder_output, decoder_hidden_state)\n",
        "\n",
        "        elif self.scoring_function == 'general':\n",
        "            decoder_hidden_state = tf.expand_dims(decoder_hidden_state,2)\n",
        "            weights = self.W1(encoder_output)\n",
        "            similarity = tf.matmul(weights, decoder_hidden_state)\n",
        "\n",
        "        elif self.scoring_function == 'concat':\n",
        "            decoder_hidden_state = tf.expand_dims(decoder_hidden_state,1)\n",
        "            similarity = self.v(tf.nn.tanh(self.W11(decoder_hidden_state) + self.W21(encoder_output)))\n",
        "            \n",
        "        attention_weights = tf.nn.softmax(similarity,axis=1)\n",
        "        context_vector = attention_weights * encoder_output\n",
        "        context_vector = tf.reduce_sum(context_vector,axis=1)\n",
        "\n",
        "        return context_vector,attention_weights"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:55:08.061622Z",
          "iopub.execute_input": "2022-07-12T14:55:08.062624Z",
          "iopub.status.idle": "2022-07-12T14:55:08.075487Z",
          "shell.execute_reply.started": "2022-07-12T14:55:08.062589Z",
          "shell.execute_reply": "2022-07-12T14:55:08.074186Z"
        },
        "trusted": true,
        "id": "w1Gccqc0Ej5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ],
      "metadata": {
        "id": "NntW1fN8Ej5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:55:10.814194Z",
          "iopub.execute_input": "2022-07-12T14:55:10.815287Z",
          "iopub.status.idle": "2022-07-12T14:55:10.855778Z",
          "shell.execute_reply.started": "2022-07-12T14:55:10.815234Z",
          "shell.execute_reply": "2022-07-12T14:55:10.854595Z"
        },
        "trusted": true,
        "id": "7axAsG_dEj5f",
        "outputId": "8e260f95-8771-47f2-89c3-310da87afe91"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "True\nTrue\nTrue\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "    def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "        super().__init__()\n",
        "        self.vocab_size = tar_vocab_size\n",
        "        self.embedding_size = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.lstm_size= dec_units\n",
        "        self.score_fun = score_fun\n",
        "        self.att_units = att_units\n",
        "        self.embedding = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_size, input_length=self.input_length,\n",
        "                           mask_zero=True, name=\"embedding_layer_encoder\")\n",
        "        self.lstm = LSTM(self.lstm_size, return_state=True, return_sequences=True, name=\"Encoder_LSTM\")\n",
        "        self.dense = Dense(self.vocab_size)\n",
        "        self.attention=Attention(self.score_fun,self.att_units)\n",
        "\n",
        "    def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "        input_embedd = self.embedding(input_to_decoder)\n",
        "        \n",
        "        context_vector,attention_weights=self.attention(state_h,encoder_output)\n",
        "       \n",
        "        concat_embed = tf.concat([input_embedd,context_vector[:,tf.newaxis,:]],2)\n",
        "        \n",
        "        lstm_output, lstm_state_h,lstm_state_c = self.lstm(concat_embed,initial_state=[state_h,state_c])\n",
        "        decoder_output = self.dense(tf.squeeze(lstm_output,axis=[1]))\n",
        "        \n",
        "        return decoder_output,lstm_state_h,lstm_state_c,attention_weights,context_vector"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:55:49.801985Z",
          "iopub.execute_input": "2022-07-12T14:55:49.803039Z",
          "iopub.status.idle": "2022-07-12T14:55:49.813113Z",
          "shell.execute_reply.started": "2022-07-12T14:55:49.802995Z",
          "shell.execute_reply": "2022-07-12T14:55:49.812163Z"
        },
        "trusted": true,
        "id": "BGQJd9VQEj5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ],
      "metadata": {
        "id": "ncVIhGj6Ej5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        tar_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    tar_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    onestepdecoder=One_Step_Decoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
        "    assert(output.shape==(batch_size,tar_vocab_size))\n",
        "    assert(state_h.shape==(batch_size,dec_units))\n",
        "    assert(state_c.shape==(batch_size,dec_units))\n",
        "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
        "    assert(context_vector.shape==(batch_size,dec_units))\n",
        "    return True\n",
        "    \n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))\n",
        "    "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:55:51.270585Z",
          "iopub.execute_input": "2022-07-12T14:55:51.270946Z",
          "iopub.status.idle": "2022-07-12T14:55:51.356779Z",
          "shell.execute_reply.started": "2022-07-12T14:55:51.270915Z",
          "shell.execute_reply": "2022-07-12T14:55:51.355906Z"
        },
        "trusted": true,
        "id": "2YKtqNgXEj5g",
        "outputId": "eb295ed1-6d54-45d1-ba26-63acf7840220"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "True\nTrue\nTrue\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "        super().__init__()\n",
        "        self.vocab_size = out_vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.dec_units = dec_units\n",
        "        self.att_units = att_units\n",
        "        self.input_length = input_length\n",
        "        self.score_fun = score_fun\n",
        "        self.onestepdecoder = One_Step_Decoder(self.vocab_size, self.embedding_dim , self.input_length,\n",
        "                                               self.dec_units ,self.score_fun ,self.att_units )\n",
        "\n",
        "\n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "        all_outputs = tf.TensorArray(tf.float32,size=self.input_length,name=\"output_array\")\n",
        "        for timestep in range(self.input_length):\n",
        "            output,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector=self.onestepdecoder(input_to_decoder[:,timestep:timestep+1],\n",
        "                                                                                                           encoder_output,decoder_hidden_state,decoder_cell_state)\n",
        "            all_outputs = all_outputs.write(timestep,output) \n",
        "        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
        "        return all_outputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:55:56.143287Z",
          "iopub.execute_input": "2022-07-12T14:55:56.144123Z",
          "iopub.status.idle": "2022-07-12T14:55:56.154075Z",
          "shell.execute_reply.started": "2022-07-12T14:55:56.144087Z",
          "shell.execute_reply": "2022-07-12T14:55:56.153001Z"
        },
        "trusted": true,
        "id": "q5jKDeVAEj5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ],
      "metadata": {
        "id": "TecMjG3UEj5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def grader_decoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    \n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "print(grader_decoder('general'))\n",
        "print(grader_decoder('concat'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T14:56:08.761763Z",
          "iopub.execute_input": "2022-07-12T14:56:08.762128Z",
          "iopub.status.idle": "2022-07-12T14:56:09.011172Z",
          "shell.execute_reply.started": "2022-07-12T14:56:08.762098Z",
          "shell.execute_reply": "2022-07-12T14:56:09.010281Z"
        },
        "trusted": true,
        "id": "WtV6TQ3wEj5g",
        "outputId": "f6fe3112-5654-40a9-de06-41c849b51b9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "True\nTrue\nTrue\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "    def __init__(self,encoder_inputs_length,decoder_inputs_length, output_vocab_size,score_fun,batch_size=128):\n",
        "        super().__init__()\n",
        "        self.batch_size=batch_size\n",
        "        self.encoder = Encoder(inp_vocab_size=vocab_size_ita+1, embedding_size=50, input_length=encoder_inputs_length,\n",
        "                               lstm_size=256)\n",
        "        self.decoder = Decoder(out_vocab_size=vocab_size_eng+1, embedding_dim=100, input_length=decoder_inputs_length,\n",
        "                               dec_units=256 ,score_fun = score_fun ,att_units=256)\n",
        "\n",
        "    def call(self,data):\n",
        "        encoder_output,state_h,state_c=self.encoder(data[0],self.encoder.initialize_states(batch_size))\n",
        "        outputs = self.decoder(data[1],encoder_output,state_h,state_c)\n",
        "        \n",
        "        return outputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T08:16:35.072440Z",
          "iopub.execute_input": "2022-07-12T08:16:35.073287Z",
          "iopub.status.idle": "2022-07-12T08:16:35.082727Z",
          "shell.execute_reply.started": "2022-07-12T08:16:35.073245Z",
          "shell.execute_reply": "2022-07-12T08:16:35.081722Z"
        },
        "trusted": true,
        "id": "QttwHYDXEj5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "https://www.tensorflow.org/tutorials/text/image_captioning#model\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    \"\"\" Custom loss function that will not consider the loss for padded zeros.\n",
        "    why are we using this, can't we use simple sparse categorical crossentropy?\n",
        "    Yes, you can use simple sparse categorical crossentropy as loss like we did in task-1. But in this loss function we are ignoring the loss\n",
        "    for the padded zeros. i.e when the input is zero then we donot need to worry what the output is. This padded zeros are added from our end\n",
        "    during preprocessing to make equal length for all the sentences.\n",
        "\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T08:16:35.088179Z",
          "iopub.execute_input": "2022-07-12T08:16:35.088820Z",
          "iopub.status.idle": "2022-07-12T08:16:35.095427Z",
          "shell.execute_reply.started": "2022-07-12T08:16:35.088793Z",
          "shell.execute_reply": "2022-07-12T08:16:35.094274Z"
        },
        "trusted": true,
        "id": "7LoxHE1wEj5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\n",
        "        self.encoder_inps = data['italian'].values\n",
        "        self.decoder_inps = data['english_inp'].values\n",
        "        self.decoder_outs = data['english_out'].values\n",
        "        self.tknizer_eng = tknizer_eng\n",
        "        self.tknizer_ita = tknizer_ita\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\n",
        "\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len+1, dtype='int32', padding='post')\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len+1, dtype='int32', padding='post')\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\n",
        "\n",
        "    def __len__(self): # your model.fit_gen requires this function\n",
        "        return len(self.encoder_inps)\n",
        "\n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\n",
        "\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indexes) // self.batch_size\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T08:16:35.096911Z",
          "iopub.execute_input": "2022-07-12T08:16:35.097496Z",
          "iopub.status.idle": "2022-07-12T08:16:35.112701Z",
          "shell.execute_reply.started": "2022-07-12T08:16:35.097454Z",
          "shell.execute_reply": "2022-07-12T08:16:35.111610Z"
        },
        "trusted": true,
        "id": "LfHQ_-IuEj5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## splitting data using the above function\n",
        "batch_size = 128\n",
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 25)\n",
        "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 25)\n",
        "\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=batch_size)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=batch_size)\n",
        "\n",
        "\n",
        "print(train_dataloader[1][0][0].shape, train_dataloader[1][0][1].shape, train_dataloader[1][1].shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T08:16:35.114330Z",
          "iopub.execute_input": "2022-07-12T08:16:35.114701Z",
          "iopub.status.idle": "2022-07-12T08:16:35.164454Z",
          "shell.execute_reply.started": "2022-07-12T08:16:35.114666Z",
          "shell.execute_reply": "2022-07-12T08:16:35.163556Z"
        },
        "trusted": true,
        "id": "3cuNVCxkEj5h",
        "outputId": "5aae74b2-0287-4ec2-8415-41804f2df76b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "(128, 25) (128, 26) (128, 26)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## here we define callbacks and model before compiling it\n",
        "log_dir = \"logs/fit/\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "earl_stp = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=5,  restore_best_weights=True)\n",
        "cb = [tensorboard_callback,earl_stp]\n",
        "\n",
        "model2 = encoder_decoder(25,26,vocab_size_eng,'dot')\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model2.compile(optimizer=optimizer,loss=loss_function)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T08:16:35.165843Z",
          "iopub.execute_input": "2022-07-12T08:16:35.166152Z",
          "iopub.status.idle": "2022-07-12T08:16:35.435653Z",
          "shell.execute_reply.started": "2022-07-12T08:16:35.166120Z",
          "shell.execute_reply": "2022-07-12T08:16:35.434634Z"
        },
        "trusted": true,
        "id": "a9qfvhUPEj5h",
        "outputId": "f7abe692-357f-4d6c-cdb0-7af4367c052f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2022-07-12 08:16:35.168346: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n2022-07-12 08:16:35.168400: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n2022-07-12 08:16:35.303689: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n2022-07-12 08:16:35.303860: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_steps=train.shape[0]//batch_size\n",
        "valid_steps=validation.shape[0]//batch_size\n",
        "model2.fit(train_dataloader,\n",
        "                     steps_per_epoch=train_steps,\n",
        "                     epochs=10,\n",
        "                     validation_data=test_dataloader,\n",
        "                     validation_steps=valid_steps,\n",
        "                     callbacks=cb,\n",
        "                     verbose=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T08:18:47.920355Z",
          "iopub.execute_input": "2022-07-12T08:18:47.920722Z",
          "iopub.status.idle": "2022-07-12T08:54:54.589542Z",
          "shell.execute_reply.started": "2022-07-12T08:18:47.920689Z",
          "shell.execute_reply": "2022-07-12T08:54:54.588507Z"
        },
        "trusted": true,
        "id": "Wxh3owp7Ej5h",
        "outputId": "cd914a3c-2222-4002-873c-564d66436f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/10\n   1/2193 [..............................] - ETA: 38:59:23 - loss: 2.5122",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2022-07-12 08:19:53.384759: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n2022-07-12 08:19:53.384814: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   2/2193 [..............................] - ETA: 55:21 - loss: 2.4721   ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2022-07-12 08:19:54.613925: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n2022-07-12 08:19:54.618931: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n2022-07-12 08:19:54.820913: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 2682 callback api events and 2680 activity events. \n2022-07-12 08:19:54.903747: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n2022-07-12 08:19:54.979518: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/train/plugins/profile/2022_07_12_08_19_54\n\n2022-07-12 08:19:55.031348: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/train/plugins/profile/2022_07_12_08_19_54/0512b6484110.trace.json.gz\n2022-07-12 08:19:55.118820: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/train/plugins/profile/2022_07_12_08_19_54\n\n2022-07-12 08:19:55.128202: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/train/plugins/profile/2022_07_12_08_19_54/0512b6484110.memory_profile.json.gz\n2022-07-12 08:19:55.131762: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/train/plugins/profile/2022_07_12_08_19_54\nDumped tool data for xplane.pb to logs/fit/train/plugins/profile/2022_07_12_08_19_54/0512b6484110.xplane.pb\nDumped tool data for overview_page.pb to logs/fit/train/plugins/profile/2022_07_12_08_19_54/0512b6484110.overview_page.pb\nDumped tool data for input_pipeline.pb to logs/fit/train/plugins/profile/2022_07_12_08_19_54/0512b6484110.input_pipeline.pb\nDumped tool data for tensorflow_stats.pb to logs/fit/train/plugins/profile/2022_07_12_08_19_54/0512b6484110.tensorflow_stats.pb\nDumped tool data for kernel_stats.pb to logs/fit/train/plugins/profile/2022_07_12_08_19_54/0512b6484110.kernel_stats.pb\n\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "2193/2193 [==============================] - 278s 98ms/step - loss: 1.0401 - val_loss: 0.7148\nEpoch 2/10\n2193/2193 [==============================] - 204s 93ms/step - loss: 0.5751 - val_loss: 0.4690\nEpoch 3/10\n2193/2193 [==============================] - 203s 93ms/step - loss: 0.3767 - val_loss: 0.3337\nEpoch 4/10\n2193/2193 [==============================] - 201s 92ms/step - loss: 0.2639 - val_loss: 0.2642\nEpoch 5/10\n2193/2193 [==============================] - 203s 92ms/step - loss: 0.1994 - val_loss: 0.2286\nEpoch 6/10\n2193/2193 [==============================] - 202s 92ms/step - loss: 0.1599 - val_loss: 0.2020\nEpoch 7/10\n2193/2193 [==============================] - 202s 92ms/step - loss: 0.1328 - val_loss: 0.1879\nEpoch 8/10\n2193/2193 [==============================] - 201s 92ms/step - loss: 0.1139 - val_loss: 0.1790\nEpoch 9/10\n2193/2193 [==============================] - 201s 92ms/step - loss: 0.0989 - val_loss: 0.1703\nEpoch 10/10\n2193/2193 [==============================] - 202s 92ms/step - loss: 0.0876 - val_loss: 0.1651\n",
          "output_type": "stream"
        },
        {
          "execution_count": 46,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7f01abd77fd0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, input_sentence):\n",
        "    inputs = input_sentence.split('')\n",
        "    encoder_seq = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "    encoder_seq = pad_sequences(encoder_seq, maxlen=25, dtype='int32', padding='post')\n",
        "    encoder_output,state_h,state_c = model.encoder(encoder_seq,model.encoder.initialize_states(1))\n",
        "    input_to_decoder = np.array(tknizer_eng.texts_to_sequences(['<start>']))\n",
        "    outputs = []\n",
        "    attention_wts = []\n",
        "    count = 0,\n",
        "    while True:\n",
        "        output,state_h,state_c,attention_weights,context_vector=model.decoder.onestepdecoder(input_to_decoder,\n",
        "                                                                                    encoder_output,state_h,state_c)\n",
        "        eng_id = tf.math.argmax(output[0]).numpy()\n",
        "        eng_word = tknizer_eng.sequences_to_texts([[eng_id]])\n",
        "        input_to_decoder = np.array(tknizer_eng.texts_to_sequences(eng_word))\n",
        "        count += 1\n",
        "        if count == 26 or eng_word[0] == '<end>':\n",
        "            break\n",
        "        outputs.append(eng_word[0])\n",
        "        attention_wts.append(tf.squeeze(attention_weights).numpy()[:len(inputs)])\n",
        "    attention_wts = np.array(attention_wts)\n",
        "    return(outputs,np.array(attention_wts))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T08:54:54.591872Z",
          "iopub.execute_input": "2022-07-12T08:54:54.592243Z",
          "iopub.status.idle": "2022-07-12T08:54:54.602977Z",
          "shell.execute_reply.started": "2022-07-12T08:54:54.592208Z",
          "shell.execute_reply": "2022-07-12T08:54:54.601966Z"
        },
        "trusted": true,
        "id": "qC44uPADEj5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## predictions on model 2\n",
        "for i,row in train.sample(4).iterrows():\n",
        "    print('='*80)\n",
        "    print(\"Italian Sentence: \" ,row['italian'].replace('<start> ','').replace(' <end>',''))\n",
        "    print(\"Acutual Translation: \" ,row['english_inp'].replace('<start> ',''))\n",
        "    print(\"Attention Weights: \")\n",
        "    outputs,attention_wts = predict(model2,row['italian'])\n",
        "    print(\"Predicted Translation: \",\" \".join(outputs))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T08:54:54.604399Z",
          "iopub.execute_input": "2022-07-12T08:54:54.605401Z",
          "iopub.status.idle": "2022-07-12T08:54:54.774086Z",
          "shell.execute_reply.started": "2022-07-12T08:54:54.605365Z",
          "shell.execute_reply": "2022-07-12T08:54:54.773062Z"
        },
        "trusted": true,
        "id": "QNwXMBkUEj5i",
        "outputId": "a85bc346-e50d-4867-fd92-7aad5bb36860"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "================================================================================\nItalian Sentence:  odio i suoi genitori\nAcutual Translation:  i hate her parents\nAttention Weights: \nPredicted Translation:  i hate your parents\n================================================================================\nItalian Sentence:  sembra che lei sappia molto\nAcutual Translation:  you seem to know a lot\nAttention Weights: \nPredicted Translation:  it sounds like you know a lot\n================================================================================\nItalian Sentence:  sei patetico\nAcutual Translation:  you are pathetic\nAttention Weights: \nPredicted Translation:  you are pathetic\n================================================================================\nItalian Sentence:  dovresti saperlo\nAcutual Translation:  you should know that\nAttention Weights: \nPredicted Translation:  you should know that\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## bleu score on model 2\n",
        "bleu_scores0 = []\n",
        "for index, row in validation.sample(1000).iterrows():\n",
        "    translation,at_wts = predict(model2,row['italian'])\n",
        "    ref = [row['english_inp'].replace('<start> ','').split()]\n",
        "    bleu_scores0.append(bleu.sentence_bleu(ref, translation))\n",
        "blscr = np.mean(bleu_scores)\n",
        "print(\"BLEU score:\", blscr)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T11:25:22.842799Z",
          "iopub.execute_input": "2022-07-12T11:25:22.843156Z",
          "iopub.status.idle": "2022-07-12T11:25:22.849385Z",
          "shell.execute_reply.started": "2022-07-12T11:25:22.843126Z",
          "shell.execute_reply": "2022-07-12T11:25:22.848137Z"
        },
        "trusted": true,
        "id": "eB9u65f4Ej5i",
        "outputId": "76b69565-f9ac-41f5-cf8b-d26ac9d2fbe8"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "BLEU score: 0.7932563189341217\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## defining callbacks and defining model 3 before compiling the model\n",
        "log_dir = \"logs3/fit/\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "earl_stp = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=3,  restore_best_weights=True)\n",
        "cb = [tensorboard_callback,earl_stp]\n",
        "\n",
        "model3 = encoder_decoder(25,26,vocab_size_eng,'general')\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model3.compile(optimizer=optimizer,loss=loss_function)"
      ],
      "metadata": {
        "id": "oGeqNuFBEj5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## fitting model 3\n",
        "model3.fit(train_dataloader, steps_per_epoch=train.shape[0]//batch_size,\n",
        "                     epochs=5,validation_data=test_dataloader,\n",
        "                     validation_steps=validation.shape[0]//batch_size,\n",
        "                     callbacks=cb,verbose=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T10:17:48.888229Z",
          "iopub.execute_input": "2022-07-12T10:17:48.888601Z",
          "iopub.status.idle": "2022-07-12T10:36:39.685451Z",
          "shell.execute_reply.started": "2022-07-12T10:17:48.888547Z",
          "shell.execute_reply": "2022-07-12T10:36:39.684506Z"
        },
        "trusted": true,
        "id": "WNOFFbqWEj5i",
        "outputId": "158e3f58-d564-4e60-8b69-c5f67b9f57a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2022-07-12 10:17:48.892648: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n2022-07-12 10:17:48.892699: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n2022-07-12 10:17:49.069703: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n2022-07-12 10:17:49.069894: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1/5\n   1/2193 [..............................] - ETA: 19:21:39 - loss: 2.5720",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2022-07-12 10:18:22.441806: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n2022-07-12 10:18:22.441866: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   2/2193 [..............................] - ETA: 56:07 - loss: 2.5091   ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2022-07-12 10:18:23.966730: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n2022-07-12 10:18:23.972713: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n2022-07-12 10:18:24.128876: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 2856 callback api events and 2854 activity events. \n2022-07-12 10:18:24.199680: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n2022-07-12 10:18:24.277743: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/train/plugins/profile/2022_07_12_10_18_24\n\n2022-07-12 10:18:24.327145: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs/fit/train/plugins/profile/2022_07_12_10_18_24/0512b6484110.trace.json.gz\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   3/2193 [..............................] - ETA: 59:31 - loss: 2.5287",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2022-07-12 10:18:24.417073: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs/fit/train/plugins/profile/2022_07_12_10_18_24\n\n2022-07-12 10:18:24.425992: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs/fit/train/plugins/profile/2022_07_12_10_18_24/0512b6484110.memory_profile.json.gz\n2022-07-12 10:18:24.429321: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs/fit/train/plugins/profile/2022_07_12_10_18_24\nDumped tool data for xplane.pb to logs/fit/train/plugins/profile/2022_07_12_10_18_24/0512b6484110.xplane.pb\nDumped tool data for overview_page.pb to logs/fit/train/plugins/profile/2022_07_12_10_18_24/0512b6484110.overview_page.pb\nDumped tool data for input_pipeline.pb to logs/fit/train/plugins/profile/2022_07_12_10_18_24/0512b6484110.input_pipeline.pb\nDumped tool data for tensorflow_stats.pb to logs/fit/train/plugins/profile/2022_07_12_10_18_24/0512b6484110.tensorflow_stats.pb\nDumped tool data for kernel_stats.pb to logs/fit/train/plugins/profile/2022_07_12_10_18_24/0512b6484110.kernel_stats.pb\n\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "2193/2193 [==============================] - 260s 104ms/step - loss: 1.0214 - val_loss: 0.7024\nEpoch 2/5\n2193/2193 [==============================] - 216s 99ms/step - loss: 0.5664 - val_loss: 0.4671\nEpoch 3/5\n2193/2193 [==============================] - 215s 98ms/step - loss: 0.3793 - val_loss: 0.3451\nEpoch 4/5\n2193/2193 [==============================] - 217s 99ms/step - loss: 0.2711 - val_loss: 0.2713\nEpoch 5/5\n2193/2193 [==============================] - 217s 99ms/step - loss: 0.2065 - val_loss: 0.2313\n",
          "output_type": "stream"
        },
        {
          "execution_count": 51,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7efce265eb50>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## sampled predictions for model 3\n",
        "for i,row in train.sample(4).iterrows():\n",
        "    print('-'*50)\n",
        "    print(\"Italian Sentence: \" ,row['italian'].replace('<start> ','').replace(' <end>',''))\n",
        "    print(\"Acutual Translation: \" ,row['english_inp'].replace('<start> ',''))\n",
        "    print(\"Attention Weights: \")\n",
        "    outputs,attention_wts = predict(model3,row['italian'])\n",
        "    print(\"Predicted Translation: \",\" \".join(outputs))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T10:36:39.687365Z",
          "iopub.execute_input": "2022-07-12T10:36:39.687664Z",
          "iopub.status.idle": "2022-07-12T10:36:39.907335Z",
          "shell.execute_reply.started": "2022-07-12T10:36:39.687637Z",
          "shell.execute_reply": "2022-07-12T10:36:39.906009Z"
        },
        "trusted": true,
        "id": "N80LqotMEj5i",
        "outputId": "ffa5d9e8-2a65-42f7-b010-b65b8a81ed47"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--------------------------------------------------\nItalian Sentence:  avresti dovuto seguire gli ordini di tom\nAcutual Translation:  you should have followed tom is orders\nAttention Weights: \nPredicted Translation:  you should have followed tom is orders\n--------------------------------------------------\nItalian Sentence:  tom dove lha sentito\nAcutual Translation:  where did tom hear that\nAttention Weights: \nPredicted Translation:  where did tom hear it\n--------------------------------------------------\nItalian Sentence:  ho appena dato a tom trenta dollari\nAcutual Translation:  i just gave tom thirty dollars\nAttention Weights: \nPredicted Translation:  i just gave tom thirty dollars\n--------------------------------------------------\nItalian Sentence:  suonerò una sonata per lei\nAcutual Translation:  i will play a sonata for you\nAttention Weights: \nPredicted Translation:  i will play a sonata for you\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## BLEU score on pred data\n",
        "bleu_scores0 = []\n",
        "for index, row in validation.sample(1000).iterrows():\n",
        "    translation,at_wts = predict(model3,row['italian'])\n",
        "    ref = [row['english_inp'].replace('<start> ','').split()]\n",
        "    bleu_scores0.append(bleu.sentence_bleu(ref, translation))\n",
        "blscr = np.mean(bleu_scores    \n",
        "print(\"BLEU score:\", blscr))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T11:22:35.028059Z",
          "iopub.execute_input": "2022-07-12T11:22:35.028702Z",
          "iopub.status.idle": "2022-07-12T11:22:35.040896Z",
          "shell.execute_reply.started": "2022-07-12T11:22:35.028655Z",
          "shell.execute_reply": "2022-07-12T11:22:35.035410Z"
        },
        "trusted": true,
        "id": "slH682cVEj5j",
        "outputId": "8fe52b75-ebf6-4815-f2fd-c967c0a33afc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "BELU score: 0.7367810563104376\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## defining callbacks and the model before compiling the model\n",
        "log_dir = \"logs4/fit/\"\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "earl_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=3,  restore_best_weights=True)\n",
        "cb = [tensorboard_callback,earl_stop]\n",
        "\n",
        "model4 = encoder_decoder(25,26,vocab_size_eng,'concat')\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model4.compile(optimizer=optimizer,loss=loss_function)"
      ],
      "metadata": {
        "id": "nmopWUYREj5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## fitting the model\n",
        "model4.fit(train_dataloader, steps_per_epoch=train.shape[0]//batch_size,\n",
        "                     epochs=5, validation_data=test_dataloader,\n",
        "                     validation_steps=validation.shape[0]//batch_size,\n",
        "                     callbacks=cb, verbose=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T10:40:34.973857Z",
          "iopub.execute_input": "2022-07-12T10:40:34.974203Z",
          "iopub.status.idle": "2022-07-12T11:02:16.505415Z",
          "shell.execute_reply.started": "2022-07-12T10:40:34.974174Z",
          "shell.execute_reply": "2022-07-12T11:02:16.504455Z"
        },
        "trusted": true,
        "id": "BMbBW3I-Ej5j",
        "outputId": "8777f424-4d2d-4e2f-84ab-7fe3089beff2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n   1/2193 [..............................] - ETA: 4:47 - loss: 1.1008",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2022-07-12 10:40:36.542364: I tensorflow/core/profiler/lib/profiler_session.cc:131] Profiler session initializing.\n2022-07-12 10:40:36.542428: I tensorflow/core/profiler/lib/profiler_session.cc:146] Profiler session started.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   2/2193 [..............................] - ETA: 1:03:39 - loss: 1.0797",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2022-07-12 10:40:36.922952: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\n2022-07-12 10:40:36.927629: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1748] CUPTI activity buffer flushed\n2022-07-12 10:40:37.102906: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 3395 callback api events and 3393 activity events. \n2022-07-12 10:40:37.184686: I tensorflow/core/profiler/lib/profiler_session.cc:164] Profiler session tear down.\n2022-07-12 10:40:37.279958: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs4/fit/train/plugins/profile/2022_07_12_10_40_37\n\n2022-07-12 10:40:37.343456: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for trace.json.gz to logs4/fit/train/plugins/profile/2022_07_12_10_40_37/0512b6484110.trace.json.gz\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "   3/2193 [..............................] - ETA: 44:27 - loss: 1.0777  ",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "2022-07-12 10:40:37.462390: I tensorflow/core/profiler/rpc/client/save_profile.cc:136] Creating directory: logs4/fit/train/plugins/profile/2022_07_12_10_40_37\n\n2022-07-12 10:40:37.473437: I tensorflow/core/profiler/rpc/client/save_profile.cc:142] Dumped gzipped tool data for memory_profile.json.gz to logs4/fit/train/plugins/profile/2022_07_12_10_40_37/0512b6484110.memory_profile.json.gz\n2022-07-12 10:40:37.478425: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: logs4/fit/train/plugins/profile/2022_07_12_10_40_37\nDumped tool data for xplane.pb to logs4/fit/train/plugins/profile/2022_07_12_10_40_37/0512b6484110.xplane.pb\nDumped tool data for overview_page.pb to logs4/fit/train/plugins/profile/2022_07_12_10_40_37/0512b6484110.overview_page.pb\nDumped tool data for input_pipeline.pb to logs4/fit/train/plugins/profile/2022_07_12_10_40_37/0512b6484110.input_pipeline.pb\nDumped tool data for tensorflow_stats.pb to logs4/fit/train/plugins/profile/2022_07_12_10_40_37/0512b6484110.tensorflow_stats.pb\nDumped tool data for kernel_stats.pb to logs4/fit/train/plugins/profile/2022_07_12_10_40_37/0512b6484110.kernel_stats.pb\n\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "2193/2193 [==============================] - 269s 123ms/step - loss: 0.7719 - val_loss: 0.5639\nEpoch 2/5\n2193/2193 [==============================] - 257s 117ms/step - loss: 0.4445 - val_loss: 0.3691\nEpoch 3/5\n2193/2193 [==============================] - 257s 117ms/step - loss: 0.2923 - val_loss: 0.2767\nEpoch 4/5\n2193/2193 [==============================] - 257s 117ms/step - loss: 0.2119 - val_loss: 0.2282\nEpoch 5/5\n2193/2193 [==============================] - 257s 117ms/step - loss: 0.1657 - val_loss: 0.2042\n",
          "output_type": "stream"
        },
        {
          "execution_count": 56,
          "output_type": "execute_result",
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7efcd9364a90>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## sampled predictions for model 4\n",
        "for i,row in train.sample(4).iterrows():\n",
        "    print('-'*50)\n",
        "    print(\"Italian Sentence: \" ,row['italian'].replace('<start> ','').replace(' <end>',''))\n",
        "    print(\"Acutual Translation: \" ,row['english_inp'].replace('<start> ',''))\n",
        "    print(\"Attention Weights: \")\n",
        "    outputs,attention_wts = predict(model4,row['italian'])\n",
        "    print(\"Predicted Translation: \",\" \".join(outputs))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T11:13:25.628076Z",
          "iopub.execute_input": "2022-07-12T11:13:25.628661Z",
          "iopub.status.idle": "2022-07-12T11:13:25.966212Z",
          "shell.execute_reply.started": "2022-07-12T11:13:25.628615Z",
          "shell.execute_reply": "2022-07-12T11:13:25.965315Z"
        },
        "trusted": true,
        "id": "CUTX-wu8Ej5j",
        "outputId": "3da73047-5ef0-46cf-9997-b2d53c2d1f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--------------------------------------------------\nItalian Sentence:  io non ho finito\nAcutual Translation:  i am not done\nAttention Weights: \nPredicted Translation:  i am not done\n--------------------------------------------------\nItalian Sentence:  tom chiese a mary di dargli un po di denaro\nAcutual Translation:  tom asked mary to give him some money\nAttention Weights: \nPredicted Translation:  tom asked mary to give me some money\n--------------------------------------------------\nItalian Sentence:  mio nonno sarebbe spesso a leggere e studiare su questa scrivania\nAcutual Translation:  my grandfather would often read and study at this desk\nAttention Weights: \nPredicted Translation:  my grandfather would often eat reading that morning on the desk\n--------------------------------------------------\nItalian Sentence:  non sei stupido\nAcutual Translation:  you are not stupid\nAttention Weights: \nPredicted Translation:  you are not stupid\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## bleu score for model 4\n",
        "bleu_scores = []\n",
        "for index, row in validation.sample(1000).iterrows():\n",
        "    translation,at_wts = predict(model4,row['italian'])\n",
        "    reference = [row['english_inp'].replace('<start> ','').split()]\n",
        "    bleu_scores.append(bleu.sentence_bleu(reference, translation))\n",
        "    \n",
        "print(\"BLEU score:\", np.mean(bleu_scores))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-07-12T11:14:22.124367Z",
          "iopub.execute_input": "2022-07-12T11:14:22.125055Z",
          "iopub.status.idle": "2022-07-12T11:15:21.429116Z",
          "shell.execute_reply.started": "2022-07-12T11:14:22.125016Z",
          "shell.execute_reply": "2022-07-12T11:15:21.428161Z"
        },
        "trusted": true,
        "id": "stS1gazAEj5j",
        "outputId": "cce67d97-a8a7-4266-afd6-65eeee681b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "BLEU score: 0.7573654946372658\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ijH3ncajEj5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***Observations***"
      ],
      "metadata": {
        "id": "Jae4fZ7BEj5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*out of concat, general and dot, dot gives the best BLEU score of arounf 0,8*\n",
        "\n",
        "*all three have more or less similar BLEU score, with DOT taking the mantle*"
      ],
      "metadata": {
        "id": "JlmrYdJiEj5k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wL9oUTPAEj5k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}